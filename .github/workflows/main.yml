on:
 schedule:
   - cron:  '*/5 * * * *' # every 5 minutes
name: Scrape Articles
jobs:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@master
    - name: prepare
      run: |
       git clone https://github.com/tasos-py/Search-Engines-Scraper;
       cd Search-Engines-Scraper;
       sudo python setup.py install;
    - name: Scrape articles 
      run: python search_engines_cli.py -e google -q "%22corona%22 site:nytimes.com &tbs=qdr:w" -o json,print -p 2
    - name: clean
      run: |
       mv /home/runner/work/Kccs/Kccs/Search-Engines-Scraper/search_engines/search_results/output.json /home/runner/work/Kccs/Kccs/output.json;
       rm -r /home/runner/work/Kccs/Kccs/Search-Engines-Scraper;
    - uses: mikeal/publish-to-github-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
